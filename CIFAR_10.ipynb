{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR-10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/rbugoo131/MLPractice/blob/master/CIFAR_10.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "1jfu4W2iJx5J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# CIFAR-10 is a common benchmark in machine learning for image recognition.\n",
        "# import library\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "import tarfile\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from urllib.request import urlretrieve\n",
        "from os.path import isfile, isdir\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xXr-0h_gKDsQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Download and extract the tarball from cifar10's website.\n",
        "def maybe_download_and_extract(dest_directory):\n",
        "  if not os.path.exists(dest_directory):\n",
        "    os.makedirs(dest_directory)\n",
        "  filename = DATA_URL.split('/')[-1]\n",
        "  filepath = os.path.join(dest_directory, filename)\n",
        "  # Example of cifar-10 download from tensroflow\n",
        "  if not os.path.exists(filepath):\n",
        "    def _progress(count, block_size, total_size):\n",
        "      sys.stdout.write('\\r>> Downloading %s %.1f%%' % (filename, float(count * block_size) / float(total_size) * 100.0))\n",
        "      sys.stdout.flush()\n",
        "    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
        "    print()\n",
        "    statinfo = os.stat(filepath)\n",
        "    print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
        "  extracted_dir_path = os.path.join(dest_directory, cifar10_dataset_folder_path)\n",
        "  print(extracted_dir_path)\n",
        "  if not os.path.exists(extracted_dir_path):\n",
        "    print('extracting')\n",
        "    tarfile.open(filepath, 'r:gz').extractall(dest_directory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GUSz8akuXzZl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DownloadProgress(tqdm):\n",
        "    last_block = 0\n",
        "\n",
        "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
        "        self.total = total_size\n",
        "        self.update((block_num - self.last_block) * block_size)\n",
        "        self.last_block = block_num"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OKqwrZt7ak76",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def unpickle(file):\n",
        "    dict = pickle.load(file, encoding='latin1')\n",
        "    return dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y8mhTOuKNepY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_cfar10_batch(cifar10_dataset_folder_path, batch_id):\n",
        "    with open(cifar10_dataset_folder_path + 'data_batch_' + str(batch_id), mode='rb') as file:\n",
        "        # note the encoding type is 'latin1'\n",
        "        #batch = pickle.load(file, encoding='latin1')\n",
        "        batch = unpickle(file)\n",
        "        \n",
        "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
        "    labels = batch['labels']\n",
        "        \n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_YfdlWzHKRyd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalize(x):\n",
        "    \"\"\"\n",
        "        argument\n",
        "            - x: input image data in numpy array [32, 32, 3]\n",
        "        return\n",
        "            - normalized x \n",
        "    \"\"\"\n",
        "    min_val = np.min(x)\n",
        "    max_val = np.max(x)\n",
        "    x = (x-min_val) / (max_val-min_val)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YHDUwvKiLYDB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_hot_encode(x):\n",
        "    \"\"\"\n",
        "        argument\n",
        "            - x: a list of labels\n",
        "        return\n",
        "            - one hot encoding matrix (number of labels, number of class)\n",
        "    \"\"\"\n",
        "    encoded = np.zeros((len(x), 10))\n",
        "    \n",
        "    for idx, val in enumerate(x):\n",
        "        encoded[idx][val] = 1\n",
        "    \n",
        "    return encoded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ajp_aPgDLbho",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _preprocess_and_save(normalize, one_hot_encode, features, labels, filename):\n",
        "    features = normalize(features)\n",
        "    labels = one_hot_encode(labels)\n",
        "\n",
        "    pickle.dump((features, labels), open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZDc2uozwPdb-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode):\n",
        "    n_batches = 5\n",
        "    valid_features = []\n",
        "    valid_labels = []\n",
        "\n",
        "    for batch_i in range(1, n_batches + 1):\n",
        "        features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_i)\n",
        "        \n",
        "        # find index to be the point as validation data in the whole dataset of the batch (10%)\n",
        "        index_of_validation = int(len(features) * 0.1)\n",
        "\n",
        "        # preprocess the 90% of the whole dataset of the batch\n",
        "        # - normalize the features\n",
        "        # - one_hot_encode the lables\n",
        "        # - save in a new file named, \"preprocess_batch_\" + batch_number\n",
        "        # - each file for each batch\n",
        "        _preprocess_and_save(normalize, one_hot_encode,\n",
        "                             features[:-index_of_validation], labels[:-index_of_validation], \n",
        "                             'preprocess_batch_' + str(batch_i) + '.py')\n",
        "\n",
        "        # unlike the training dataset, validation dataset will be added through all batch dataset\n",
        "        # - take 10% of the whold dataset of the batch\n",
        "        # - add them into a list of\n",
        "        #   - valid_features\n",
        "        #   - valid_labels\n",
        "        valid_features.extend(features[-index_of_validation:])\n",
        "        valid_labels.extend(labels[-index_of_validation:])\n",
        "\n",
        "    # preprocess the all stacked validation dataset\n",
        "    _preprocess_and_save(normalize, one_hot_encode,\n",
        "                         np.array(valid_features), np.array(valid_labels),\n",
        "                         'preprocess_validation.py')\n",
        "\n",
        "    # load the test dataset\n",
        "    with open(cifar10_dataset_folder_path + 'test_batch', mode='rb') as file:\n",
        "        batch = unpickle(file)\n",
        "        #batch = pickle.load(file, encoding='latin1')\n",
        "\n",
        "    # preprocess the testing data\n",
        "    test_features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
        "    test_labels = batch['labels']\n",
        "\n",
        "    # Preprocess and Save all testing data\n",
        "    _preprocess_and_save(normalize, one_hot_encode,\n",
        "                         np.array(test_features), np.array(test_labels),\n",
        "                         'preprocess_training.py')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YP_onq5udTsh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_label_names():\n",
        "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WEB1lmfnSFlW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def display_stats(cifar10_dataset_folder_path, batch_id, sample_id):\n",
        "    features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_id)\n",
        "    \n",
        "    if not (0 <= sample_id < len(features)):\n",
        "        print('{} samples in batch {}.  {} is out of range.'.format(len(features), batch_id, sample_id))\n",
        "        return None\n",
        "\n",
        "    print('\\nStats of batch #{}:'.format(batch_id))\n",
        "    print('# of Samples: {}\\n'.format(len(features)))\n",
        "    \n",
        "    label_names = load_label_names()\n",
        "    label_counts = dict(zip(*np.unique(labels, return_counts=True)))\n",
        "    for key, value in label_counts.items():\n",
        "        print('Label Counts of [{}]({}) : {}'.format(key, label_names[key].upper(), value))\n",
        "    \n",
        "    sample_image = features[sample_id]\n",
        "    sample_label = labels[sample_id]\n",
        "    \n",
        "    print('\\nExample of Image {}:'.format(sample_id))\n",
        "    print('Image - Min Value: {} Max Value: {}'.format(sample_image.min(), sample_image.max()))\n",
        "    print('Image - Shape: {}'.format(sample_image.shape))\n",
        "    print('Label - Label Id: {} Name: {}'.format(sample_label, label_names[sample_label]))\n",
        "    \n",
        "    plt.imshow(sample_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VODuU-eSkJoU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
        "    loss = sess.run(cost, \n",
        "                    feed_dict={\n",
        "                        x: feature_batch,\n",
        "                        y: label_batch,\n",
        "                        keep_prob: 1.\n",
        "                    })\n",
        "    valid_acc = sess.run(accuracy, \n",
        "                         feed_dict={\n",
        "                             x: valid_features,\n",
        "                             y: valid_labels,\n",
        "                             keep_prob: 1.\n",
        "                         })\n",
        "    \n",
        "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, valid_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4B9ZQSP_kiZU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def batch_features_labels(features, labels, batch_size):\n",
        "    \"\"\"\n",
        "    Split features and labels into batches\n",
        "    \"\"\"\n",
        "    for start in range(0, len(features), batch_size):\n",
        "        end = min(start + batch_size, len(features))\n",
        "        yield features[start:end], labels[start:end]\n",
        "\n",
        "def load_preprocess_training_batch(batch_id, batch_size):\n",
        "    \"\"\"\n",
        "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
        "    \"\"\"\n",
        "    filename = 'preprocess_batch_' + str(batch_id) + '.py'\n",
        "    features, labels = pickle.load(open(filename, mode='rb'))\n",
        "\n",
        "    # Return the training data in batches of size <batch_size> or less\n",
        "    return batch_features_labels(features, labels, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7KhltnhYdt1w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The function is self-defined for weight and bias\n",
        "def weight_variable(shape):\n",
        "    initial = tf.truncated_normal(shape, stddev=0.5)\n",
        "    return tf.Variable(initial)\n",
        "\n",
        "def bias_variable(shape):\n",
        "    initial = tf.constant(0.05, shape=shape)\n",
        "    return tf.Variable(initial)\n",
        "    \n",
        "# self-defined convolution function layer \n",
        "def conv2d(x, W):\n",
        "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "# self-defined max-pooling function layer \n",
        "def max_pool_2x2(x):\n",
        "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mkYdOODakJRq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
        "    run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
        "    session.run(optimizer, \n",
        "                feed_dict={ x: feature_batch, \n",
        "                            y: label_batch, \n",
        "                            keep_prob: keep_probability \n",
        "                          }, \n",
        "                options=run_options\n",
        "               )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NvMF7om5J9m2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# CIFAR-10 dataset's website\n",
        "DATA_URL = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
        "\n",
        "\n",
        "# Folder for downloaded CIFAR-10 dataset\n",
        "train_dir = './dataset/cifar10/'\n",
        "\n",
        "#cifar10_dataset_folder_path = train_dir + 'cifar-10-batches-bin/'\n",
        "cifar10_dataset_folder_path = 'cifar-10-batches-py/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g9swRcqEPh7A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#maybe_download_and_extract(train_dir)\n",
        "\"\"\" \n",
        "    check if the data (zip) file is already downloaded\n",
        "    if not, download it from \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\" and save as cifar-10-python.tar.gz\n",
        "\"\"\"\n",
        "if not isfile('cifar-10-python.tar.gz'):\n",
        "    with DownloadProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
        "        urlretrieve(\n",
        "            DATA_URL,\n",
        "            'cifar-10-python.tar.gz',\n",
        "            pbar.hook)\n",
        "\n",
        "if not isdir(cifar10_dataset_folder_path):\n",
        "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
        "        tar.extractall()\n",
        "        tar.close()\n",
        "\n",
        "preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LotbIx3dSIXt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "42132647-7598-4a8b-d9f0-fde5b3bb2fcd"
      },
      "cell_type": "code",
      "source": [
        "# Explore the dataset\n",
        "batch_id = 3\n",
        "sample_id = 7000\n",
        "display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Stats of batch #3:\n",
            "# of Samples: 10000\n",
            "\n",
            "Label Counts of [0](AIRPLANE) : 994\n",
            "Label Counts of [1](AUTOMOBILE) : 1042\n",
            "Label Counts of [2](BIRD) : 965\n",
            "Label Counts of [3](CAT) : 997\n",
            "Label Counts of [4](DEER) : 990\n",
            "Label Counts of [5](DOG) : 1029\n",
            "Label Counts of [6](FROG) : 978\n",
            "Label Counts of [7](HORSE) : 1015\n",
            "Label Counts of [8](SHIP) : 961\n",
            "Label Counts of [9](TRUCK) : 1029\n",
            "\n",
            "Example of Image 7000:\n",
            "Image - Min Value: 24 Max Value: 252\n",
            "Image - Shape: (32, 32, 3)\n",
            "Label - Label Id: 0 Name: airplane\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFCxFRAgKliIiBAVLERHC/wMJnnjNdbI6nwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f2e29ec17f0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "OblSM_6gStL5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_features, valid_labels = pickle.load(open('preprocess_validation.py', mode='rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EJyCNz1qdpc4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Remove previous weights, bias, inputs, etc..\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Inputs\n",
        "x = tf.placeholder(tf.float32, shape=(None, 32, 32, 3), name='input_image')\n",
        "y = tf.placeholder(tf.float32, shape=(None, 10), name='output_label')\n",
        "keep_prob = tf.placeholder(tf.float32, name='keep_prob')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vZpRyPWVfVTX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#DNN type\n",
        "\n",
        "with tf.name_scope('FirstConvolutionLayer'):\n",
        "    W_conv1 = weight_variable([3, 3, 3, 64])\n",
        "    b_conv1 = bias_variable([64])\n",
        "    h_conv1 = tf.nn.relu(conv2d(x, W_conv1) + b_conv1)\n",
        "    h_pool1 = max_pool_2x2(h_conv1)\n",
        "    conv1_bn = tf.layers.batch_normalization(h_pool1)\n",
        "\n",
        "with tf.name_scope('SecondConvolutionLayer'):\n",
        "    W_conv2 = weight_variable([3, 3, 64, 128])\n",
        "    b_conv2 = bias_variable([128])\n",
        "    h_conv2 = tf.nn.relu(conv2d(conv1_bn, W_conv2) + b_conv2)\n",
        "    h_pool2 = max_pool_2x2(h_conv2)\n",
        "    conv2_bn = tf.layers.batch_normalization(h_pool2)\n",
        "\n",
        "with tf.name_scope('ThirdConvolutionLayer'):\n",
        "    W_conv3 = weight_variable([5, 5, 128, 256])\n",
        "    b_conv3 = bias_variable([256])\n",
        "    h_conv3 = tf.nn.relu(conv2d(conv2_bn, W_conv3) + b_conv3)\n",
        "    h_pool3 = max_pool_2x2(h_conv3)\n",
        "    conv3_bn = tf.layers.batch_normalization(h_pool3)\n",
        "\n",
        "with tf.name_scope('ForthConvolutionLayer'):\n",
        "    W_conv4 = weight_variable([5, 5, 256, 512])\n",
        "    b_conv4 = bias_variable([512])\n",
        "    h_conv4 = tf.nn.relu(conv2d(conv3_bn, W_conv4) + b_conv4)\n",
        "    h_pool4 = max_pool_2x2(h_conv4)\n",
        "    conv4_bn = tf.layers.batch_normalization(h_pool4)\n",
        "    \n",
        "with tf.name_scope('FifthConvolutionLayer'):\n",
        "    W_conv5 = weight_variable([7, 7, 512, 1024])\n",
        "    b_conv5 = bias_variable([1024])\n",
        "    h_conv5 = tf.nn.relu(conv2d(conv4_bn, W_conv5) + b_conv5)\n",
        "    h_pool5 = max_pool_2x2(h_conv5)\n",
        "    conv5_bn = tf.layers.batch_normalization(h_pool5)\n",
        "\n",
        "with tf.name_scope('SixthConvolutionLayer'):\n",
        "    W_conv6 = weight_variable([7, 7, 1024, 1024])\n",
        "    b_conv6 = bias_variable([1024])\n",
        "    h_conv6 = tf.nn.relu(conv2d(conv5_bn, W_conv6) + b_conv6)\n",
        "    h_pool6 = max_pool_2x2(h_conv6)\n",
        "    conv6_bn = tf.layers.batch_normalization(h_pool6)    \n",
        "    \n",
        "# flatten\n",
        "flat = tf.contrib.layers.flatten(conv6_bn)  \n",
        "\n",
        "# fully connected 1\n",
        "full1 = tf.contrib.layers.fully_connected(inputs=flat, num_outputs=1024, activation_fn=tf.nn.relu)\n",
        "full1 = tf.nn.dropout(full1, keep_prob)\n",
        "full1 = tf.layers.batch_normalization(full1)\n",
        "\n",
        "# fully connected 2\n",
        "full2 = tf.contrib.layers.fully_connected(inputs=full1, num_outputs=512, activation_fn=tf.nn.relu)\n",
        "full2 = tf.nn.dropout(full2, keep_prob)\n",
        "full2 = tf.layers.batch_normalization(full2)\n",
        "\n",
        "# fully connected 3\n",
        "full3 = tf.contrib.layers.fully_connected(inputs=full2, num_outputs=256, activation_fn=tf.nn.relu)\n",
        "full3 = tf.nn.dropout(full3, keep_prob)\n",
        "full3 = tf.layers.batch_normalization(full3)    \n",
        "\n",
        "# fully connected 4\n",
        "full4 = tf.contrib.layers.fully_connected(inputs=full3, num_outputs=128, activation_fn=tf.nn.relu)\n",
        "full4 = tf.nn.dropout(full4, keep_prob)\n",
        "full4 = tf.layers.batch_normalization(full4)        \n",
        "\n",
        "# output\n",
        "out = tf.contrib.layers.fully_connected(inputs=full4, num_outputs=10, activation_fn=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3wrJSNot3VtC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# PSHNN Type\n",
        "with tf.name_scope('SNN1'):\n",
        "    W_conv1_1 = weight_variable([3, 3, 3, 64])\n",
        "    b_conv1_1 = bias_variable([64])\n",
        "    h_conv1_1 = tf.nn.relu(conv2d(x, W_conv1_1) + b_conv1_1)\n",
        "    h_pool1_1 = max_pool_2x2(h_conv1_1)\n",
        "    \n",
        "    W_conv1_2 = weight_variable([3, 3, 64, 128])\n",
        "    b_conv1_2 = bias_variable([128])\n",
        "    h_conv1_2 = tf.nn.relu(conv2d(h_pool1_1, W_conv1_2) + b_conv1_2)\n",
        "    h_pool1_2 = max_pool_2x2(h_conv1_2)\n",
        "    conv1_bn = tf.layers.batch_normalization(h_pool1_2)\n",
        "    \n",
        "    # flatten\n",
        "    flat1 = tf.contrib.layers.flatten(conv1_bn)  \n",
        "    \n",
        "    # fully connected 1\n",
        "    full1 = tf.contrib.layers.fully_connected(inputs=flat1, num_outputs=512, activation_fn=tf.nn.relu)\n",
        "    full1 = tf.nn.dropout(full1, keep_prob)\n",
        "    full1 = tf.layers.batch_normalization(full1)\n",
        "    \n",
        "    # output\n",
        "    snn1_out = tf.contrib.layers.fully_connected(inputs=full1, num_outputs=10, activation_fn=tf.nn.sigmoid)\n",
        "    \n",
        "with tf.name_scope('SNN2'):\n",
        "    W_conv2_1 = weight_variable([5, 5, 3, 128])\n",
        "    b_conv2_1 = bias_variable([128])\n",
        "    h_conv2_1 = tf.nn.relu(conv2d(x, W_conv2_1) + b_conv2_1)\n",
        "    h_pool2_1 = max_pool_2x2(h_conv2_1)\n",
        "    \n",
        "    W_conv2_2 = weight_variable([5, 5, 128, 512])\n",
        "    b_conv2_2 = bias_variable([512])\n",
        "    h_conv2_2 = tf.nn.relu(conv2d(h_pool2_1, W_conv2_2) + b_conv2_2)\n",
        "    h_pool2_2 = max_pool_2x2(h_conv2_2)\n",
        "    conv2_bn = tf.layers.batch_normalization(h_pool2_2)\n",
        "    \n",
        "    # flatten\n",
        "    flat2 = tf.contrib.layers.flatten(conv2_bn)  \n",
        "    \n",
        "    # fully connected 1\n",
        "    full2 = tf.contrib.layers.fully_connected(inputs=flat2, num_outputs=1024, activation_fn=tf.nn.relu)\n",
        "    full2 = tf.nn.dropout(full2, keep_prob)\n",
        "    full2 = tf.layers.batch_normalization(full2)\n",
        "    \n",
        "    # output\n",
        "    snn2_out = tf.contrib.layers.fully_connected(inputs=full2, num_outputs=10, activation_fn=tf.nn.sigmoid)\n",
        "    \n",
        "with tf.name_scope('SNN3'):\n",
        "    W_conv3_1 = weight_variable([7, 7, 3, 128])\n",
        "    b_conv3_1 = bias_variable([128])\n",
        "    h_conv3_1 = tf.nn.relu(conv2d(x, W_conv3_1) + b_conv3_1)\n",
        "    h_pool3_1 = max_pool_2x2(h_conv3_1)\n",
        "    \n",
        "    W_conv3_2 = weight_variable([7, 7, 128, 256])\n",
        "    b_conv3_2 = bias_variable([256])\n",
        "    h_conv3_2 = tf.nn.relu(conv2d(h_pool3_1, W_conv3_2) + b_conv3_2)\n",
        "    h_pool3_2 = max_pool_2x2(h_conv3_2)\n",
        "    conv3_bn = tf.layers.batch_normalization(h_pool3_2)\n",
        "    \n",
        "    # flatten\n",
        "    flat3 = tf.contrib.layers.flatten(conv3_bn)  \n",
        "    \n",
        "    # fully connected 1\n",
        "    full3 = tf.contrib.layers.fully_connected(inputs=flat3, num_outputs=2048, activation_fn=tf.nn.relu)\n",
        "    full3 = tf.nn.dropout(full3, keep_prob)\n",
        "    full3 = tf.layers.batch_normalization(full3)\n",
        "    \n",
        "    # output\n",
        "    snn3_out = tf.contrib.layers.fully_connected(inputs=full3, num_outputs=10, activation_fn=tf.nn.sigmoid)\n",
        "  \n",
        "#out = snn1_out\n",
        "#W1 = tf.Variable(tf.truncated_normal([10],0, stddev=0.5))\n",
        "#W2 = tf.Variable(tf.truncated_normal([10],0, stddev=0.5))\n",
        "#out = tf.add(tf.multiply(snn1_out, W1),tf.multiply(snn2_out, W2))\n",
        "#out = snn3_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TEnUwGcuiybk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#global parameter setting\n",
        "epochs = 10\n",
        "batch_size = 1024\n",
        "keep_probability = 0.7\n",
        "learning_rate = 0.0001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ei4RyhEfi3uJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loss and Optimizer\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out, labels=y))\n",
        "#loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=snn1_out, labels=y))\n",
        "#loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=snn2_out, labels=y))\n",
        "#loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=snn3_out, labels=y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
        "\n",
        "# Accuracy\n",
        "correct_pred = tf.equal(tf.argmax(out, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y3clhSSDjcR2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1472
        },
        "outputId": "2575514b-b819-4747-c1c6-7ce0ebd736bd"
      },
      "cell_type": "code",
      "source": [
        "save_model_path = './image_classification'\n",
        "\n",
        "print('Training...')\n",
        "with tf.Session() as sess:\n",
        "    # Initializing the variables\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    # Training cycle\n",
        "    for epoch in range(epochs):\n",
        "        # Loop over all batches\n",
        "        n_batches = 5\n",
        "        for batch_i in range(1, n_batches + 1):\n",
        "            for batch_features, batch_labels in load_preprocess_training_batch(batch_i, batch_size):\n",
        "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
        "                \n",
        "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
        "            print_stats(sess, batch_features, batch_labels, loss, accuracy)\n",
        "            \n",
        "    # Save Model\n",
        "    saver = tf.train.Saver()\n",
        "    save_path = saver.save(sess, save_model_path)\n",
        "\n",
        "    sess.close()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Epoch  1, CIFAR-10 Batch 1:  Loss: 91302.4375 Validation Accuracy: 0.101200\n",
            "Epoch  1, CIFAR-10 Batch 2:  Loss: 33083.3672 Validation Accuracy: 0.112800\n",
            "Epoch  1, CIFAR-10 Batch 3:  Loss: 22327.9336 Validation Accuracy: 0.157800\n",
            "Epoch  1, CIFAR-10 Batch 4:  Loss: 12724.2461 Validation Accuracy: 0.160600\n",
            "Epoch  1, CIFAR-10 Batch 5:  Loss:  8733.0420 Validation Accuracy: 0.156600\n",
            "Epoch  2, CIFAR-10 Batch 1:  Loss:  7482.7471 Validation Accuracy: 0.163000\n",
            "Epoch  2, CIFAR-10 Batch 2:  Loss:  6131.0435 Validation Accuracy: 0.144200\n",
            "Epoch  2, CIFAR-10 Batch 3:  Loss:  5247.9429 Validation Accuracy: 0.155600\n",
            "Epoch  2, CIFAR-10 Batch 4:  Loss:  4355.5342 Validation Accuracy: 0.159800\n",
            "Epoch  2, CIFAR-10 Batch 5:  Loss:  4106.0474 Validation Accuracy: 0.163400\n",
            "Epoch  3, CIFAR-10 Batch 1:  Loss:  4222.2153 Validation Accuracy: 0.163600\n",
            "Epoch  3, CIFAR-10 Batch 2:  Loss:  3456.6238 Validation Accuracy: 0.155800\n",
            "Epoch  3, CIFAR-10 Batch 3:  Loss:  3379.9170 Validation Accuracy: 0.156000\n",
            "Epoch  3, CIFAR-10 Batch 4:  Loss:  2585.2388 Validation Accuracy: 0.150800\n",
            "Epoch  3, CIFAR-10 Batch 5:  Loss:  2086.9524 Validation Accuracy: 0.142600\n",
            "Epoch  4, CIFAR-10 Batch 1:  Loss:  1384.6187 Validation Accuracy: 0.115000\n",
            "Epoch  4, CIFAR-10 Batch 2:  Loss:   665.8780 Validation Accuracy: 0.093800\n",
            "Epoch  4, CIFAR-10 Batch 3:  Loss:   319.6016 Validation Accuracy: 0.092200\n",
            "Epoch  4, CIFAR-10 Batch 4:  Loss:   184.7150 Validation Accuracy: 0.095400\n",
            "Epoch  4, CIFAR-10 Batch 5:  Loss:   130.1524 Validation Accuracy: 0.090800\n",
            "Epoch  5, CIFAR-10 Batch 1:  Loss:   113.3836 Validation Accuracy: 0.092400\n",
            "Epoch  5, CIFAR-10 Batch 2:  Loss:    75.9973 Validation Accuracy: 0.093200\n",
            "Epoch  5, CIFAR-10 Batch 3:  Loss:    69.9239 Validation Accuracy: 0.093800\n",
            "Epoch  5, CIFAR-10 Batch 4:  Loss:    50.8050 Validation Accuracy: 0.096000\n",
            "Epoch  5, CIFAR-10 Batch 5:  Loss:    53.7396 Validation Accuracy: 0.096000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-6750a2658b20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batches\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mload_preprocess_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mtrain_neural_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_probability\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch {:>2}, CIFAR-10 Batch {}:  '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-8dba1c64b8b6>\u001b[0m in \u001b[0;36mtrain_neural_network\u001b[0;34m(session, optimizer, keep_probability, feature_batch, label_batch)\u001b[0m\n\u001b[1;32m      6\u001b[0m                             \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeep_probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                           }, \n\u001b[0;32m----> 8\u001b[0;31m                 \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "PwoBaRXX3X03",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**DNN result with initial weight [-0.5, 0.5], bias = 0.05, 6 convolution layer, out lyaer actfunction = NONE : **\n",
        "\n",
        "Epoch 10, CIFAR-10 Batch 1:  Loss:     0.0408 Validation Accuracy: 0.727400\n",
        "\n",
        "Epoch 10, CIFAR-10 Batch 2:  Loss:     0.0180 Validation Accuracy: 0.722000\n",
        "\n",
        "Epoch 10, CIFAR-10 Batch 3:  Loss:     0.0310 Validation Accuracy: 0.734600\n",
        "\n",
        "Epoch 10, CIFAR-10 Batch 4:  Loss:     0.0561 Validation Accuracy: 0.733800\n",
        "\n",
        "Epoch 10, CIFAR-10 Batch 5:  Loss:     0.0111 Validation Accuracy: 0.737200\n",
        "\n",
        "**SNN1 result with initial weight [-0.5, 0.5], bias = 0.05, 2 convolution layer, out lyaer actfunction = sigmoid : **\n",
        "[10][1024][0.7][0.0001]\n",
        "\n",
        "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.8182 Validation Accuracy: 0.513000\n",
        "\n",
        "Epoch 10, CIFAR-10 Batch 2:  Loss:     1.8133 Validation Accuracy: 0.518600\n",
        "\n",
        "Epoch 10, CIFAR-10 Batch 3:  Loss:     1.7966 Validation Accuracy: 0.518200\n",
        "\n",
        "Epoch 10, CIFAR-10 Batch 4:  Loss:     1.8009 Validation Accuracy: 0.510200\n",
        "\n",
        "Epoch 10, CIFAR-10 Batch 5:  Loss:     1.8044 Validation Accuracy: 0.516000\n",
        "\n",
        "**SNN2 result with initial weight [-0.5, 0.5], bias = 0.05, 2 convolution layer, out lyaer actfunction = sigmoid : **\n",
        "[10][4096][0.7][0.00001]\n",
        "\n",
        "Epoch 10, CIFAR-10 Batch 1:  Loss:     2.2376 Validation Accuracy: 0.179200\n",
        "\n",
        "Epoch 10, CIFAR-10 Batch 2:  Loss:     2.2470 Validation Accuracy: 0.192000\n",
        "\n",
        "Epoch 10, CIFAR-10 Batch 3:  Loss:     2.2351 Validation Accuracy: 0.201600\n",
        "\n",
        "Epoch 10, CIFAR-10 Batch 4:  Loss:     2.2476 Validation Accuracy: 0.200000\n",
        "\n",
        "Epoch 10, CIFAR-10 Batch 5:  Loss:     2.2406 Validation Accuracy: 0.187000\n",
        "\n",
        "**SNN3 result with initial weight [-0.5, 0.5], bias = 0.05, 2 convolution layer, out lyaer actfunction = sigmoid : **[10][1024][0.7][0.00001]\n",
        "\n",
        "Epoch 10, CIFAR-10 Batch 1:  Loss:     2.2281 Validation Accuracy: 0.157400\n",
        "\n",
        "Epoch 10, CIFAR-10 Batch 2:  Loss:     2.2336 Validation Accuracy: 0.143400\n",
        "\n",
        "Epoch 10, CIFAR-10 Batch 3:  Loss:     2.2420 Validation Accuracy: 0.155000\n",
        "\n",
        "Epoch 10, CIFAR-10 Batch 4:  Loss:     2.2417 Validation Accuracy: 0.157800\n",
        "\n",
        "Epoch 10, CIFAR-10 Batch 5:  Loss:     2.2403 Validation Accuracy: 0.134000"
      ]
    },
    {
      "metadata": {
        "id": "Jxmtjdq63d1d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def display_image_predictions(features, labels, predictions):\n",
        "    n_classes = 10\n",
        "    label_names = _load_label_names()\n",
        "    label_binarizer = LabelBinarizer()\n",
        "    label_binarizer.fit(range(n_classes))\n",
        "    label_ids = label_binarizer.inverse_transform(np.array(labels))\n",
        "\n",
        "    fig, axies = plt.subplots(nrows=4, ncols=2)\n",
        "    fig.tight_layout()\n",
        "    fig.suptitle('Softmax Predictions', fontsize=20, y=1.1)\n",
        "\n",
        "    n_predictions = 3\n",
        "    margin = 0.05\n",
        "    ind = np.arange(n_predictions)\n",
        "    width = (1. - 2. * margin) / n_predictions\n",
        "\n",
        "    for image_i, (feature, label_id, pred_indicies, pred_values) in enumerate(zip(features, label_ids, predictions.indices, predictions.values)):\n",
        "        pred_names = [label_names[pred_i] for pred_i in pred_indicies]\n",
        "        correct_name = label_names[label_id]\n",
        "\n",
        "        axies[image_i][0].imshow(feature*255)\n",
        "        axies[image_i][0].set_title(correct_name)\n",
        "        axies[image_i][0].set_axis_off()\n",
        "\n",
        "        axies[image_i][1].barh(ind + margin, pred_values[::-1], width)\n",
        "        axies[image_i][1].set_yticks(ind + margin)\n",
        "        axies[image_i][1].set_yticklabels(pred_names[::-1])\n",
        "        axies[image_i][1].set_xticks([0, 0.5, 1.0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fw6NyVUZmUkF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "a1725df6-1d33-47d3-f92a-76f1454bb337"
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "save_model_path = './image_classification'\n",
        "batch_size = 64\n",
        "n_samples = 10\n",
        "top_n_predictions = 5\n",
        "\n",
        "test_features, test_labels = pickle.load(open('preprocess_training.py', mode='rb'))\n",
        "loaded_graph = tf.Graph()\n",
        "\n",
        "with tf.Session(graph=loaded_graph) as sess:\n",
        "    # Load model\n",
        "    loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
        "    loader.restore(sess, save_model_path)\n",
        "\n",
        "    # Get Tensors from loaded model\n",
        "    loaded_x = loaded_graph.get_tensor_by_name('input_image:0')\n",
        "    loaded_y = loaded_graph.get_tensor_by_name('output_label:0')\n",
        "    loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
        "    #loaded_out = loaded_graph.get_tensor_by_name('out:0')\n",
        "    loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
        "\n",
        "    # Get accuracy in batches for memory limitations\n",
        "    test_batch_acc_total = 0\n",
        "    test_batch_count = 0\n",
        "\n",
        "    for train_feature_batch, train_label_batch in batch_features_labels(test_features, test_labels, batch_size):\n",
        "        test_batch_acc_total += sess.run(\n",
        "            loaded_acc,\n",
        "            feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
        "        test_batch_count += 1\n",
        "\n",
        "    print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
        "\n",
        "    # Print Random Samples\n",
        "    #random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
        "    #random_test_predictions = sess.run(\n",
        "    #    tf.nn.top_k(tf.nn.softmax(loaded_out), top_n_predictions),\n",
        "    #    feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
        "    #display_image_predictions(random_test_features, random_test_labels, random_test_predictions)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./image_classification\n",
            "Testing Accuracy: 0.10041799363057324\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G3dOnQXu4hR7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**DNN result with initial weight [-0.5, 0.5], bias = 0.05, 6 convolution layer, out lyaer actfunction = NONE : **\n",
        "> Testing Accuracy: 0.7239251592356688\n",
        "\n",
        "**SNN1 result with initial weight [-0.5, 0.5], bias = 0.05, 2 convolution layer, out lyaer actfunction = sigmoid : **\n",
        "> Testing Accuracy: 0.4307324840764331\n",
        "\n",
        "**SNN2 result with initial weight [-0.5, 0.5], bias = 0.05, 2 convolution layer, out lyaer actfunction = sigmoid : **\n",
        "> Testing Accuracy: 0.2770700636942675\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "yle7_G_28E6n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "6473415d-b447-4705-f0c9-d411ddb1f63c"
      },
      "cell_type": "code",
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize    \n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn't guaranteed\n",
        "gpu = GPUs[0]\n",
        "\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print('GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB'.format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "printm()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/45/99/837428d26b47ebd6b66d6e1b180e98ec4a557767a93a81a02ea9d6242611/GPUtil-1.3.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gputil) (1.14.6)\n",
            "Building wheels for collected packages: gputil\n",
            "  Running setup.py bdist_wheel for gputil ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/17/0f/04/b79c006972335e35472c0b835ed52bfc0815258d409f560108\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.3.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.7)\n",
            "Collecting humanize\n",
            "  Downloading https://files.pythonhosted.org/packages/8c/e0/e512e4ac6d091fc990bbe13f9e0378f34cf6eecd1c6c268c9e598dcf5bb9/humanize-0.5.1.tar.gz\n",
            "Building wheels for collected packages: humanize\n",
            "  Running setup.py bdist_wheel for humanize ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/69/86/6c/f8b8593bc273ec4b0c653d3827f7482bb2001a2781a73b7f44\n",
            "Successfully built humanize\n",
            "Installing collected packages: humanize\n",
            "Successfully installed humanize-0.5.1\n",
            "Gen RAM Free: 11.5 GB  I Proc size: 3.4 GB\n",
            "GPU RAM Free: 3037MB | Used: 8402MB | Util  73% | Total 11439MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QqWcZarDul_3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}